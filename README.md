# BreastCancerDetectionUsingCNN

Cancer, a leading cause of mortality worldwide, poses a significant threat to global health. Among its various forms, breast cancer stands out as one of the most prevalent and fatal types. Early detection and accurate diagnosis are pivotal in enhancing survival rates. Mammography, a widely used screening tool, has been instrumental in detecting breast cancer. Recent advancements in machine learning techniques have enabled more efficient analysis of mammography images, aiding in precise diagnosis.
This research paper delves into the realm of breast cancer diagnosis, focusing on the intricate analysis of mammogram images. The study commences with a comprehensive understanding of the underlying data, followed by intricate visualization techniques applied to mammogram images. Leveraging this foundational knowledge, the research endeavours to construct a sophisticated yet accessible machine learning model. The primary objective is to differentiate between benign and malignant tumors using mammography images, facilitating accurate diagnosis. By employing a simplified machine learning approach, the study aims to enhance the efficiency of breast cancer identification without compromising accuracy.
In essence, this research contributes to the ongoing efforts in the field by offering a nuanced perspective. By exploring the potential of a simpler yet effective machine learning model, this study not only advances the methodology but also contributes to the practicality of implementing these models in real-world clinical settings. The outcomes of this research hold the promise of aiding radiologists in their diagnostic endeavours, ultimately improving the prospects for breast cancer patients through early and precise detection.

Initially, I experimented with different hyperparameters, starting with a batch size of 32, a learning rate of 0.01, and 20 epochs. Surprisingly, this configuration yielded an accuracy of 59%. Undeterred, I tweaked the batch size, reducing it to 8, while keeping the learning rate constant at 0.01 and maintaining 20 epochs, but the improvement was marginal, reaching 60% accuracy. I decided to further refine the batch size, setting it to 4, maintaining the learning rate at 0.01, and still training for 20 epochs. This adjustment proved fruitful, pushing the accuracy to 62%. Seeking more significant progress, I made a pivotal change, decreasing the learning rate to 0.001 and extending the training duration to 40 epochs. This strategic move resulted in a remarkable accuracy boost, achieving 84.19% on the training dataset and 88.21% on the test dataset, marking a substantial advancement.
In my quest for better results, I ventured into experimenting with the VGG16 model. I initiated the training with a batch size of 8 and 20 epochs, but the outcomes were underwhelming, with the model's accuracy plateauing at 58%. Undaunted, I continued my exploration, adjusting the learning rate to 0.001, reducing the batch size to 4, and extending the training period to 40 epochs. This modification proved pivotal, significantly enhancing the model's performance, resulting in an impressive 68.8% accuracy on the training data and a commendable 68% accuracy on the test data. Through these iterative experiments and thoughtful adjustments, I gained valuable insights into the nuances of model training, gradually achieving substantial improvements in accuracy and enhancing my understanding of deep learning techniques.
Using Alexnet model, I could get the F1 score as 1, which is indeed a good score confirming that my model was able to predict correct labels accurately.
